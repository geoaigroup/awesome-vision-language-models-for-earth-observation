# A curated list of Visual Language Models papers and resources for Earth Observation (VLM4EO) [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/geoaigroup/awesome-vision-language-models-for-earth-observation/)  

This list is created and maintained by [Ali Koteich](https://github.com/alikoteich) and [Hasan Moughnieh](https://geogroup.ai/author/hasan-moughnieh/) from the GEOspatial Artificial Intelligence ([GEOAI](https://geogroup.ai/)) research group at the National Center for Remote Sensing - CNRS, Lebanon.  

We encourage you to contribute to this project according to the following [guidelines](https://github.com/sindresorhus/awesome/blob/main/contributing.md).  

---**If you find this repository useful, please consider giving it a ‚≠ê**

**Table Of Contents**
- [A curated list of Visual Language Models papers and resources for Earth Observation (VLM4EO) ](#a-curated-list-of-visual-language-models-papers-and-resources-for-earth-observation-vlm4eo-)
  - [Foundation Models](#foundation-models)
  - [Image Captioning](#image-captioning)
  - [Text-Image Retrieval](#text-image-retrieval)
  - [Visual Grounding](#visual-grounding)
  - [Visual Question Answering](#visual-question-answering)
  - [Vision-Language Remote Sensing Datasets](#vision-language-remote-sensing-datasets)
  - [Related Repositories \& Libraries](#related-repositories--libraries)

## Foundation Models
| Year | Title                                                                                                       | Paper                                                                                                        | Code                                                                      | Venue                                         |
|------|-------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------|-----------------------------------------------|
| 2025 | Beyond the Visible: Multispectral Vision-Language Learning for Earth Observation                           | [paper](https://arxiv.org/abs/2503.15969)                                                                      |                                                                          |                                               |
| 2024 | EarthGPT: A Universal Multi-modal Large Language Model for Multi-sensor Image Comprehension in Remote Sensing Domain   | [paper](https://arxiv.org/abs/2401.16822)                                                         |                         |                                               |
| 2024 | RemoteCLIP: A Vision Language Foundation Model for Remote Sensing                                                      | [paper](https://arxiv.org/abs/2306.11029)                                                         | [code](https://github.com/ChenDelong1999/RemoteCLIP)                    |
| 2024 | Remote Sensing ChatGPT: Solving Remote Sensing Tasks with ChatGPT and Visual Models                                    | [paper](https://arxiv.org/abs/2401.09083)                                                         | [code](https://github.com/HaonanGuo/Remote-Sensing-ChatGPT)            |                                                 |
| 2024 | SkyEyeGPT: Unifying Remote Sensing Vision-Language Tasks via Instruction Tuning with Large Language Model              | [paper](https://arxiv.org/abs/2401.09712)                                                         | [code](https://github.com/ZhanYang-nwpu/SkyEyeGPT)                        |                                               |
| 2024 | VHM: Versatile and Honest Vision Language Model for Remote Sensing Image Analysis                                      | [paper](https://arxiv.org/abs/2403.20213)                                                         | [code](https://github.com/opendatalab/VHM)                              |                                                  |
| 2023 | GeoChat: Grounded Large Vision-Language Model for Remote Sensing                                                       | [paper](https://arxiv.org/abs/2311.15826)                                                         |   [code](https://github.com/mbzuai-oryx/geochat)                          |                                               |
| 2023 | Remote Sensing Vision-Language Foundation Models without Annotations via Ground Remote Alignment                       | [paper](https://export.arxiv.org/abs/2312.06960)                                                  |                                                                          |                                               |

## Image Captioning
| Year | Title                                                                                                       | Paper                                                                                                        | Code                                                                      | Venue                                         |
|------|-------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------|-----------------------------------------------|
| 2024 | A Lightweight Transformer for Remote Sensing Image Change Captioning                                        | [paper](https://arxiv.org/abs/2405.06598)                                                                    | [code](https://github.com/sundongwei/Lite_Chag2cap)
| 2024 | RSCaMa: Remote Sensing Image Change Captioning with State Space Model                                       | [paper](https://arxiv.org/abs/2404.18895)                                                                    | [code](https://github.com/Chen-Yang-Liu/RSCaMa)                           |                                                |
| 2023 | Captioning Remote Sensing Images Using Transformer Architecture                                             | [paper](https://ieeexplore.ieee.org/document/10067039/)                                                     |                                                                           | International Conference on Artificial Intelligence in Information and Communication |
| 2023 | Multi-Source Interactive Stair Attention for Remote Sensing Image Captioning                                | [paper](https://www.mdpi.com/2072-4292/15/3/579)                                                             |                                                                           | MDPI Remote Sensing                           |
| 2023 | Progressive Scale-aware Network for Remote sensing Image Change Captioning                                  | [paper](https://arxiv.org/abs/2303.00355)                                                                    |                                                                           |                                               |
| 2023 | Towards Unsupervised Remote Sensing Image Captioning and Retrieval with Pre-Trained Language Models         | [paper](https://www.anlp.jp/proceedings/annual_meeting/2023/pdf_dir/B10-4.pdf)                              |                                                                           | Proceedings of the Japanese Association for Natural Language Processing |
| 2022 | A Joint-Training Two-Stage Method for Remote Sensing Image Captioning                                       | [paper](https://ieeexplore.ieee.org/document/9961235)                                                        |                                                                           | IEEE TGRS                                     |
| 2022 | A Mask-Guided Transformer Network with Topic Token for Remote Sensing Image Captioning                      | [paper](https://www.mdpi.com/2072-4292/14/12/2939)                                                           |                                                                           | MDPI Remote Sensing                           |
| 2022 | Change Captioning: A New Paradigm for Multitemporal Remote Sensing Image Analysis                           | [paper](https://ieeexplore.ieee.org/document/9847254)                                                        |                                                                           | IEEE TGRS                                     |
| 2022 | Exploring Transformer and Multilabel Classification for Remote Sensing Image Captioning                     | [paper](https://ieeexplore.ieee.org/document/9855519)                                                        | [code](https://gitlab.lrz.de/ai4eo/captioningMultilabel.)                 | IEEE GRSL                                     |
| 2022 | Generating the captions for remote sensing images: A spatial-channel attention based memory-guided transformer approach | [paper](https://www.sciencedirect.com/science/article/abs/pii/S0952197622002317)                            | [code](https://github.com/GauravGajbhiye/SCAMET_RSIC)                     | Engineering Applications of Artificial Intelligence |
| 2022 | Global Visual Feature and Linguistic State Guided Attention for Remote Sensing Image                        | [paper](https://ieeexplore.ieee.org/document/9632558)                                                        |                                                                           | IEEE TGRS                                     |
| 2022 | High-Resolution Remote Sensing Image Captioning Based on Structured Attention                               | [paper](https://ieeexplore.ieee.org/document/9400386)                                                        |                                                                           | IEEE TGRS                                     |
| 2022 | Meta captioning: A meta learning based remote sensing image captioning framework                            | [paper](https://www.sciencedirect.com/science/article/abs/pii/S0924271622000351)                            | [code](https://github.com/QiaoqiaoYang/MetaCaptioning.)                   | Elsevier PHOTO                                |
| 2022 | Multiscale Multiinteraction Network for Remote Sensing Image Captioning                                     | [paper](https://ieeexplore.ieee.org/document/9720234)                                                        |                                                                           | IEEE JSTARS                                   |
| 2022 | NWPU-Captions Dataset and MLCA-Net for Remote Sensing Image Captioning                                      | [paper](https://ieeexplore.ieee.org/document/9866055)                                                        | [code](https://github.com/HaiyanHuang98/NWPU-Captions)                    | IEEE TGRS                                     |
| 2022 | Recurrent Attention and Semantic Gate for Remote Sensing Image Captioning                                   | [paper](https://ieeexplore.ieee.org/document/9515452)                                                        |                                                                           | IEEE TGRS                                     |
| 2022 | Remote Sensing Image Change Captioning With Dual-Branch Transformers: A New Method and a Large Scale Dataset | [paper](https://ieeexplore.ieee.org/document/9934924)                                                        |                                                                           | IEEE TGRS                                     |
| 2022 | Transforming remote sensing images to textual descriptions                                                  | [paper](https://www.sciencedirect.com/science/article/pii/S0303243422000678)                                |                                                                           | Int J Appl Earth Obs Geoinf                   |
| 2022 | Using Neural Encoder-Decoder Models with Continuous Outputs for Remote Sensing Image Captioning             | [paper](https://ieeexplore.ieee.org/document/9714367)                                                        |                                                                           | IEEE Access                                   |
| 2021 | A Novel SVM-Based Decoder for Remote Sensing Image Captioning                                               | [paper](https://ieeexplore.ieee.org/document/9521989)                                                        |                                                                           | IEEE TGRS                                     |
| 2021 | SD-RSIC: Summarization Driven Deep Remote Sensing Image Captioning                                          | [paper](https://ieeexplore.ieee.org/document/9239371)                                                        | [code](https://git.tu-berlin.de/rsim/SD-RSIC)                             | IEEE TGRS                                     |
| 2021 | Truncation Cross Entropy Loss for Remote Sensing Image Captioning                                           | [paper](https://ieeexplore.ieee.org/document/9153154)                                                        |                                                                           | IEEE TGRS                                     |
| 2021 | Word-Sentence Framework for Remote Sensing Image Captioning                                                 | [paper](https://ieeexplore.ieee.org/document/9308980/?denied=)                                               |                                                                           | IEEE TGRS                                     |
| 2020 | A multi-level attention model for remote sensing image captions                                             | [paper](https://www.mdpi.com/2072-4292/12/6/939)                                                             |                                                                           | MDPI Remote Sensing                           |
| 2020 | Remote sensing image captioning via Variational Autoencoder and Reinforcement Learning                      | [paper](https://www.sciencedirect.com/science/article/abs/pii/S0950705120302586)                            |                                                                           | Elservier Knowledge-Based Systems             |
| 2020 | Toward Remote Sensing Image Retrieval Under a Deep Image Captioning Perspective                             | [paper](https://ieeexplore.ieee.org/document/9154525)                                                        |                                                                           | IEEE JSTARS                                   |
| 2019 | LAM: Remote sensing image captioning with attention-based language model                                    | [paper](https://ieeexplore.ieee.org/document/8930629)                                                        |                                                                           | IEEE TGRS                                     |
| 2019 | Learning to Caption Remote Sensing Images by Geospatial Feature Driven Attention Mechanism                  | [paper](https://ieeexplore.ieee.org/document/8780492)                                                        |                                                                           | IEEE JSTARS                                   |
| 2019 | Remote Sensing Image Captioning by Deep Reinforcement Learning with Geospatial Features                     | [paper](https://ieeexplore.ieee.org/document/8820076)                                                        |                                                                           | IEEE TGRS                                     |





## Text-Image Retrieval

| Year | Title                                                                                                        | Paper                                                                                                        | Code                                                                      | Venue                                         |
|------|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------|-----------------------------------------------|
| 2024 | Composed Image Retrieval for Remote Sensing | [paper](https://arxiv.org/abs/2405.15587) | [code](https://github.com/billpsomas/rscir) | |
| 2024 | Multi-Spectral Remote Sensing Image Retrieval using Geospatial Foundation Models                            | [paper](https://arxiv.org/abs/2403.02059)                                                                    | [code](https://github.com/IBM/remote-sensing-image-retrieval)              |                                               |
| 2024 | Transcending Fusion: A Multi-Scale Alignment Method for Remote Sensing Image-Text Retrieval | [paper](https://arxiv.org/abs/2405.18959)                                                                           | [code](https://github.com/yr666666/MSA)                                          |                                       |
| 2023 | A Prior Instruction Representation Framework for Remote Sensing Image-text Retrieval | [paper](https://dl.acm.org/doi/10.1145/3581783.3612374)                                                           |    [code](https://github.com/Zjut-MultimediaPlus/PIR-pytorch)                                                    | ACM MM 2023 (Oral)                             |
| 2023 | A Fusion Encoder with Multi-Task Guidance for Cross-Modal Text‚ÄìImage Retrieval in Remote Sensing | [paper](https://www.mdpi.com/2072-4292/15/18/4637)                                                           |                                                      | MDPI Remote Sensing                            |
| 2023 | An End-to-End Framework Based on Vision-Language Fusion for Remote Sensing Cross-Modal Text-Image Retrieval | [paper](https://www.mdpi.com/2227-7390/11/10/2279)                                                           |                                                                           | MDPI Mathematics                             |
| 2023 | Contrasting Dual Transformer Architectures for Multi-Modal Remote Sensing Image Retrieval                   | [paper](https://www.mdpi.com/2076-3417/13/1/282)                                                             |                                                                           | MDPI Applied Sciences                        |
| 2023 | Hypersphere-Based Remote Sensing Cross-Modal Text‚ÄìImage Retrieval via Curriculum Learning | [paper](https://ieeexplore.ieee.org/document/10261223)                                                           |       [code](https://github.com/ZhangWeihang99/HVSA)      | IEEE TGRS                           |
| 2023 | Parameter-Efficient Transfer Learning for Remote Sensing Image-Text Retrieval | [paper](https://ieeexplore.ieee.org/document/10231134)                                                           |                                                      | IEEE TGRS                           |
| 2023 | Reducing Semantic Confusion: Scene-aware Aggregation Network for Remote Sensing Cross-modal Retrieval       | [paper](https://dl.acm.org/doi/abs/10.1145/3591106.3592236)                                                  | [code](https://github.com/kinshingpoon/SWAN-pytorch)                     | ICMR'23                                      |
| 2022 | A Lightweight Multi-Scale Crossmodal Text-Image Retrieval Method in Remote Sensing                          | [paper](https://ieeexplore.ieee.org/document/9594840)                                                        | [code](https://github.com/xiaoyuan1996/retrievalSystem)                  | IEEE TGRS                                    |
| 2022 | An Unsupervised Cross-Modal Hashing Method Robust to Noisy Training Image-Text Correspondences in Remote Sensing | [paper](https://ieeexplore.ieee.org/document/9897500)                                                        | [code](https://git.tu-berlin.de/rsim/chnr)                               | IEEE ICIP                                    |
| 2022 | CLIP-RS: A Cross-modal Remote Sensing Image Retrieval Based on CLIP, a Northern Virginia Case Study          | [paper](https://vtechworks.lib.vt.edu/handle/10919/110853)                                                   |                                                                           | Virginia Polytechnic Institute and State University |
| 2022 | Knowledge-Aware Cross-Modal Text-Image Retrieval for Remote Sensing Images                                  | [paper](https://ceur-ws.org/Vol-3207/paper4.pdf)                                                             |                                                                           |                                               |
| 2022 | MCRN: A Multi-source Cross-modal Retrieval Network for remote sensing                                       | [paper](https://www.sciencedirect.com/science/article/pii/S156984322200259X)                                | [code](https://github.com/xiaoyuan1996/MCRN)                             | Int J Appl Earth Obs Geoinf                   |
| 2022 | Multilanguage Transformer for Improved Text to Remote Sensing Image Retrieval                               | [paper](https://ieeexplore.ieee.org/document/9925582)                                                        |                                                                           | IEEE JSTARS                                   |
| 2022 | Multisource Data Reconstruction-Based Deep Unsupervised Hashing for Unisource Remote Sensing Image Retrieval | [Paper](https://ieeexplore.ieee.org/abstract/document/10001754)                                              | [code](https://github.com/sunyuxi/MrHash)                                | IEEE TGRS                                    |
| 2022 | Remote Sensing Cross-Modal Text-Image Retrieval Based on Global and Local Information                       | [paper](https://ieeexplore.ieee.org/document/9745546)                                                        | [code](https://github.com/xiaoyuan1996/GaLR)                             | IEEE TGRS                                    |
| 2022 | Unsupervised Contrastive Hashing for Cross-Modal Retrieval in Remote Sensing                                | [paper](https://ieeexplore.ieee.org/document/9746251)                                                        | [code](https://git.tu-berlin.de/rsim/duch)                               | IEEE ICASSP                                  |
| 2021 | Exploring a Fine-Grained Multiscale Method for Cross-Modal Remote Sensing Image Retrieval                    | [paper](https://ieeexplore.ieee.org/document/9437331)                                                        |[code](https://github.com/xiaoyuan1996/AMFMN)                                                                           | IEEE TGRS                                    |
| 2020 | Deep unsupervised embedding for remote sensing image retrieval using textual cues                           | [paper](https://www.mdpi.com/2076-3417/10/24/8931)                                                           |                                                                           | MDPI Applied Sciences                         |
| 2020 | TextRS: Deep bidirectional triplet network for matching text to remote sensing images                       | [paper](https://www.mdpi.com/2072-4292/12/3/405)                                                             |                                                                           | MDPI Remote Sensing                           |
| 2020 | Toward Remote Sensing Image Retrieval under a Deep Image Captioning Perspective                             | [paper](https://ieeexplore.ieee.org/document/9154525)                                                        |                                                                           | IEEE JSTARS                                   |


## Visual Grounding
| Year | Title                                                                                   | Paper                                                                                                           | Code                                                  | Venue    |
|------|-----------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------|-------------------------------------------------------|----------|
| 2024 | GeoGround: A Unified Large Vision-Language Model. for Remote Sensing Visual Grounding   | [paper](https://arxiv.org/abs/2411.11904)                                                                        | [code](https://github.com/zytx121/GeoGround)         |             |
| 2023 | LaLGA: Multi-Scale Language-Aware Visual Grounding on Remote Sensing Data               | [paper](https://www.researchgate.net/publication/373146282_LaLGA_Multi-Scale_LanguageAware_Visual_Grounding_on_Remote_Sensing_Data) | [code](https://github.com/like413/OPT-RSVG)           |          |
| 2023 | Text2Seg: Remote Sensing Image Semantic Segmentation via Text-Guided Visual Foundation Models | [paper](https://arxiv.org/abs/2304.10597)                                                                       | [code](https://github.com/Douglas2Code/Text2Seg)      |          |
| 2022 | RSVG: Exploring Data and Models for Visual Grounding on Remote Sensing Data             | [paper](https://ieeexplore.ieee.org/document/10056343)                                                                       | [code](https://github.com/ZhanYang-nwpu/RSVG-pytorch) | IEEE TGRS |
| 2022 | Visual Grounding in Remote Sensing Images | [paper](https://dl.acm.org/doi/abs/10.1145/3503161.3548316)                                                                       |       |  ACM MM   |


## Visual Question Answering
| Year | Title                                                                                                       | Paper                                                                                                  | Code                                                                                             | Venue                                                |
|------|-------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|------------------------------------------------------|
| 2023 | A Spatial Hierarchical Reasoning Network for Remote Sensing Visual Question Answering                      | [paper](https://ieeexplore.ieee.org/document/10018408)                                                 |                                                                                                  | IEEE TGRS                                            |
| 2023 | EarthVQA: Towards Queryable Earth via Relational Reasoning-Based Remote Sensing Visual Question Answering   | [paper](https://arxiv.org/pdf/2312.12222.pdf)                                                 |    [code](https://junjue-wang.github.io/homepage/EarthVQA)      | AAAI 2024 |
| 2023 | LIT-4-RSVQA: Lightweight Transformer-based Visual Question Answering in Remote Sensing                     | [paper](https://arxiv.org/abs/2306.00758)                                                              | [code](https://git.tu-berlin.de/rsim/lit4rsvqa)                                                  | IEEE IGARSS                                          |
| 2023 | Multistep Question-Driven Visual Question Answering for Remote Sensing                                      | [paper](https://ieeexplore.ieee.org/document/10242124)                                        | [code](https://github.com/MeimeiZhang-data/MQVQA)                | IEEE TGRS
| 2023 | RSGPT: A Remote Sensing Vision Language Model and Benchmark                                                 | [paper](https://arxiv.org/abs/2307.15266)                                                                    | [code](https://github.com/Lavender105/RSGPT)                              |                                               |
| 2023 | RSAdapter: Adapting Multimodal Models for Remote Sensing Visual Question Answering                         | [paper](https://arxiv.org/abs/2310.13120)                                                              | [code](https://github.com/Y-D-Wang/RSAdapter)                                                    |                                                      |
| 2022 | Bi-Modal Transformer-Based Approach for Visual Question Answering in Remote Sensing Imagery                | [paper](https://ieeexplore.ieee.org/document/9832935)                                                  |                                                                                                  | IEEE TGRS                                            |
| 2022 | Change Detection Meets Visual Question Answering                                                          | [paper](https://ieeexplore.ieee.org/abstract/document/9901476)                                         | [code](https://github.com/YZHJessica/CDVQA)                                                     | IEEE TGRS                                            |
| 2022 | From Easy to Hard: Learning Language-guided Curriculum for Visual Question Answering on Remote Sensing Data| [paper](https://ieeexplore.ieee.org/abstract/document/9771224)                                         | [code](https://github.com/YZHJessica/VQA-easy2hard)                                             | IEEE TGRS                                            |
| 2022 | Language Transformers for Remote Sensing Visual Question Answering                                        | [paper](https://ieeexplore.ieee.org/document/9884036)                                                  |                                                                                                  | IEEE IGARSS                                          |
| 2022 | Multi-Modal Fusion Transformer for Visual Question Answering in Remote Sensing                            | [paper](https://arxiv.org/abs/2210.04510)                                                              | [code](https://git.tu-berlin.de/rsim/multi-modal-fusion-transformer-for-vqa-in-rs)              | SPIE Image and Signal Processing for Remote Sensing  |
| 2022 | Mutual Attention Inception Network for Remote Sensing Visual Question Answering                           | [paper](https://ieeexplore.ieee.org/document/9444570)                                                  | [code](https://github.com/spectralpublic/RSIVQA)                                                | IEEE TGRS                                            |
| 2022 | Prompt-RSVQA: Prompting visual context to a language model for Remote Sensing Visual Question Answering   | [paper](https://ieeexplore.ieee.org/document/9857471)                                                  |                                                                                                  | CVPRW                                                |
| 2021 | How to find a good image-text embedding for remote sensing visual question answering?                     | [paper](https://arxiv.org/abs/2109.11848)                                                              |                                                                                                  | CEUR Workshop Proceedings                            |
| 2021 | Mutual Attention Inception Network for Remote Sensing Visual Question Answering                           | [paper](https://ieeexplore.ieee.org/document/9444570)                                                  | [code](https://github.com/spectralpublic/RSIVQA)                                                      | IEEE TGRS                                          |
| 2021 | RSVQA meets BigEarthNet: a new, large-scale, visual question answering dataset for remote sensing         | [paper](https://ieeexplore.ieee.org/document/9553307)                                                  | [code](https://github.com/syvlo/RSVQAxBEN)                                                      | IEEE IGARSS                                          |
| 2020 | RSVQA: Visual Question Answering for Remote Sensing Data                                                  | [paper](https://ieeexplore.ieee.org/abstract/document/9088993)                                         | [code](https://github.com/syvlo/RSVQA)                                                          | IEEE TGRS                                            |


## Vision-Language Remote Sensing Datasets
| Name | Link | Paper Link | Description |
| --- | --- | --- | --- |
| RS5M: A Large Scale Vision-Language Dataset for Remote Sensing Vision-Language Foundation Model| [Link](https://github.com/om-ai-lab/RS5M) | [Paper Link](https://arxiv.org/abs/2306.11300) | Size: 5 million remote sensing images with English descriptions <br>Resolution : 256 x 256 <br> Platforms:  11 publicly available image-text paired dataset<br>|
| SkyScript: A Large and Semantically Diverse Vision-Language Dataset for Remote Sensing| [Link](https://github.com/wangzhecheng/SkyScript)  | [paper Link](https://arxiv.org/abs/2312.12856) | Size : 5.2 million remote sensing image-text pairs in total, covering more than 29K distinct semantic tags                                              |                     
| Remote Sensing Visual Question Answering Low Resolution Dataset(RSVQA LR)| [Link](https://zenodo.org/record/6344334) | [Paper Link](https://arxiv.org/abs/2003.07333) | Size: 772 images & 77,232 questions and answers <br>Resolution : 256 x 256 <br> Platforms: Sentinel-2 and Open Street Map<br>Use: Remote Sensing Visual Question Answering <br>|
| Remote Sensing Visual Question Answering High Resolution Dataset(RSVQA HR)| [Link](https://zenodo.org/record/6344367) | [Paper Link](https://arxiv.org/abs/2003.07333) | Size: 10,659 images & 955,664 questions and answers <br>Resolution : 512 x 512  <br> Platforms: USGS and Open Street Map<br>Use: Remote Sensing Visual Question Answering <br>|
| Remote Sensing Visual Question Answering BigEarthNet Dataset (RSVQA x BEN)| [Link](https://zenodo.org/record/5084904) | [Paper Link](https://rsvqa.sylvainlobry.com/IGARSS21.pdf) | Size: 140,758,150 image/question/answer triplets <br>Resolution : High-resolution (15cm)  <br> Platforms: Sentinel-2, BigEarthNet and Open Street Map<br>Use: Remote Sensing Visual Question Answering <br>|
| Remote Sensing Image Visual Question Answering (RSIVQA)| [Link](https://github.com/spectralpublic/RSIVQA) | [Paper Link](https://ieeexplore.ieee.org/document/9444570) | Size: 37,264 images and 111,134 image-question-answer triplets <br>A small part of RSIVQA is annotated by human. Others are automatically generated using existing scene classification datasets and object detection datasets<br>Use: Remote Sensing Visual Question Answering <br>|
| FloodNet Visual Question Answering Dataset| [Link](https://drive.google.com/drive/folders/1g1r419bWBe4GEF-7si5DqWCjxiC8ErnY?usp=sharing) | [Paper Link](https://arxiv.org/abs/2012.02951) | Size: 11,000 question-image pairs <br>Resolution :  224 x 224  <br> Platforms: UAV-DJI Mavic Pro quadcopters, after Hurricane Harvey<br>Use: Remote Sensing Visual Question Answering <br>|
| Change Detection-Based Visual Question Answering Dataset| [Link](https://github.com/YZHJessica/CDVQA) | [Paper Link](https://ieeexplore.ieee.org/abstract/document/9901476) | Size: 2,968 pairs of multitemporal images and more than 122,000 question‚Äìanswer pairs <br> Classes: 6 <br> Resolution :  512√ó512 pixels  <br> Platforms: It is based on semantic change detection dataset (SECOND)<br>Use: Remote Sensing Visual Question Answering <br>|
| LAION-EO | [link](https://huggingface.co/datasets/mikonvergence/LAION-EO) | [Paper Link](https://arxiv.org/abs/2309.15535) | Size : 24,933 samples with 40.1% english captions as well as other common languages from LAION-5B <br> mean height of 633.0 pixels (up to 9,999) and mean width of 843.7 pixels (up to 19,687) <br> Platforms : Based on LAION-5B <br> |
| CapERA: Captioning Events in Aerial Videos | [Link](https://www.github.com/yakoubbazi/CapEra) | [Paper Link](https://www.mdpi.com/2072-4292/15/8/2139) | Size : 2864 videos and 14,320 captions, where each video is paired with five unique captions |
| Remote Sensing Image Captioning Dataset (RSICap) | [link]( https://github.com/Lavender105/RSGPT) | [Paper Link](https://arxiv.org/abs/2307.15266) |  RSICap comprises 2,585 human-annotated captions with rich and high-quality information <br> This dataset offers detailed descriptions for each image, encompassing scene descriptions (e.g., residential area, airport, or farmland) as well as object information (e.g., color, shape, quantity, absolute position, etc) <br> |
| Remote Sensing Image Captioning Evaluation Dataset (RSIEval)| [link]( https://github.com/Lavender105/RSGPT) | [Paper Link](https://arxiv.org/abs/2307.15266) | 100 human-annotated captions and 936 visual question-answer pairs with rich information and open-ended questions and answers.<br> Can be used for Image Captioning and Visual Question-Answering tasks <br> |
| Revised Remote Sensing Image Captioning Dataset (RSCID)| [Link](https://drive.google.com/open?id=0B1jt7lJDEXy3aE90cG9YSl9ScUk) | [Paper Link](https://arxiv.org/pdf/1712.07835) | Size: 10,921 images with five captions per image <br> Number of Classes: 30 <br>Resolution :  224 x 224  <br> Platforms: Google Earth, Baidu Map, MapABC and  Tianditu<br>Use: Remote Sensing Image Captioning <br>|
| Revised University of California Merced dataset (UCM-Captions)| [Link](https://mega.nz/folder/wCpSzSoS#RXzIlrv--TDt3ENZdKN8JA) | [Paper Link](https://ieeexplore.ieee.org/document/7546397) | Size: 2,100 images with five captions per image <br> Number of Classes: 21 <br>Resolution :  256 x 256  <br> Platforms: USGS National Map Urban Area Imagery collection<br>Use: Remote Sensing Image Captioning <br>|
| Revised Sydney-Captions Dataset| [Link](https://pan.baidu.com/s/1hujEmcG) | [Paper Link](https://ieeexplore.ieee.org/document/7546397) | Size: 613 images with five captions per image <br> Number of Classes: 7 <br>Resolution :  500 x 500<br> Platforms: GoogleEarth<br> Use: Remote Sensing Image Captioning <br>|
| LEVIR-CC dataset| [Link](https://drive.google.com/drive/folders/1cEv-BXISfWjw1RTzL39uBojH7atjLdCG?usp=sharing) | [Paper Link](https://ieeexplore.ieee.org/document/9934924) | Size: 10,077 pairs of RS images and 50,385 corresponding sentences <br> Number of Classes: 10  <br>Resolution :  1024 √ó 1024 pixels<br> Platforms: Beihang University<br> Use: Remote Sensing Image Captioning <br>|
| NWPU-Captions dataset| [images_Link](https://pan.baidu.com/s/1hmuWwnfPy2eZxxGxt6XuSg), [info_Link](https://github.com/HaiyanHuang98/NWPU-Captions/blob/main/dataset_nwpu.json) | [Paper Link](https://ieeexplore.ieee.org/document/9866055/) | Size: 31,500 images with 157,500 sentences <br> Number of Classes: 45  <br>Resolution : 256 x 256 pixels<br> Platforms: based on NWPU-RESISC45 dataset <br> Use: Remote Sensing Image Captioning <br>|
| Remote sensing Image-Text Match dataset (RSITMD)| [Link](https://drive.google.com/file/d/1NJY86TAAUd8BVs7hyteImv8I2_Lh95W6/view?usp=sharing) | [Paper Link](https://ieeexplore.ieee.org/document/9437331) | Size: 23,715 captions for 4,743 images <br> Number of Classes: 32 <br>Resolution :  500 x 500  <br> Platforms: RSCID and GoogleEarth <br> Use: Remote Sensing Image-Text Retrieval<br>|
| PatterNet| [Link](https://nuisteducn1-my.sharepoint.com/:u:/g/personal/zhouwx_nuist_edu_cn/EYSPYqBztbBBqS27B7uM_mEB3R9maNJze8M1Qg9Q6cnPBQ?e=MSf977) | [Paper Link](https://arxiv.org/abs/1706.03424) | Size: 30,400 images <br> Number of Classes: 38 <br>Resolution :  256 x 256  <br> Platforms: Google Earth imagery and via the Google Map AP <br> Use: Remote Sensing Image Retrieval<br>|
| Dense Labeling Remote Sensing Dataset (DLRSD)| [Link](https://nuisteducn1-my.sharepoint.com/:u:/g/personal/zhouwx_nuist_edu_cn/EVjxkus-aXRGnLFxWA5K440B_k-WNNR5-BT1I6LTojuG7g?e=rgSMHi) | [Paper Link](https://www.mdpi.com/2072-4292/10/6/964) | Size: 2,100 images <br> Number of Classes: 21 <br>Resolution :  256 x 256  <br> Platforms: Extension of the UC Merced  <br> Use: Remote Sensing Image Retrieval (RSIR), Classification and Semantic Segmentation<br>|
| Dior-Remote Sensing Visual Grounding Dataset (RSVGD) | [Link](https://drive.google.com/drive/folders/1hTqtYsC6B-m4ED2ewx5oKuYZV13EoJp_) | [Paper Link](https://ieeexplore.ieee.org/document/10056343) | Size: 38,320 RS image-query pairs and 17,402 RS images<br>Number of Classes: 20<br>Resolution : 800 x 800  <br> Platforms: DIOR dataset  <br> Use: Remote Sensing Visual Grounding <br>|
| OPT-RSVG Dataset  | [link](https://drive.google.com/drive/folders/1e_wOtkruWAB2JXR7aqaMZMrM75IkjqCA?usp=drive_link) | [Paper Link](https://www.researchgate.net/publication/373146282_LaLGA_Multi-Scale_LanguageAware_Visual_Grounding_on_Remote_Sensing_Data) | Size : 25,452 Images and 48,952 expression in English and Chinese <br> Number of Classes : 14 <br> Resolution : 800 x 800 | 
| Visual Grounding in Remote Sensing Images | [link](https://sunyuxi.github.io/publication/GeoVG) | [Paper Link](https://dl.acm.org/doi/abs/10.1145/3503161.3548316) | Size : 4,239 images including 5,994 object instances and 7,933 referring expressions <br> Images are 1024√ó1024 pixels<br>Platforms: multiple sensors and platforms (e.g. Google Earth)  <br> |
| Remote Sensing Image Scene Classification (NWPU-RESISC45) | [Link](https://1drv.ms/u/s!AmgKYzARBl5ca3HNaHIlzp_IXjs) | [Paper Link](https://arxiv.org/pdf/1703.00121v1.pdf) | Size: 31,500 images <br>Number of Classes: 45<br>Resolution : 256 x 256 pixels  <br> Platforms: Google Earth  <br> Use: Remote Sensing Image Scene Classification  <br>|

<!--
| High Resolution Remote Sensing Detection (HRRSD) | [Link](https://drive.google.com/open?id=1bffECWdpa0jg2Jnm7V0oCyFFh0N-EIkr) | [Paper Link](https://ieeexplore.ieee.org/document/8676107) | Size: 21,761 images and 55,740 object instances <br>Number of Classes: 13<br>Resolution : spatial resolution from 0.15-m to 1.2-m  <br> Platforms: Google Earth and Baidu Map  <br> Use: Remote Sensing Object Detection <br>|
| Dior Dataset | [Link](https://drive.google.com/open?id=1UdlgHk49iu6WpcJ5467iT-UqNPpx__CC) | [Paper Link](https://arxiv.org/abs/1909.00133) | Size: 23,463 images and 192,518 object instances <br>Number of Classes: 20<br>Resolution : 800 x 800  <br> Platforms: Technical University of Munich ¬∑ Northwestern Polytechnical University ¬∑ Zhengzhou Institute of Surveying and Mapping  <br> Use: Remote Sensing Object Detection <br>|
| Remote Sensing Object Detection (RSOD) |Each object has its own link: [aircraft](http://pan.baidu.com/s/1eRWFV5C), [playground](http://pan.baidu.com/s/1nuD4KLb), [overpass](http://pan.baidu.com/s/1kVKAFB5) and [oiltank](http://pan.baidu.com/s/1kUZn4zX) | [Paper Link](http://ieeexplore.ieee.org/abstract/document/7827088/) | Size: 976 images and 6,950 object instances<br>Number of Classes: 4<br>Resolution : range from 0.3m to 3m  <br> Platforms: Google Earth and Tianditu  <br> Use: Remote Sensing Object Detection <br>|
| DOTA-v1.0 | [Training_Set](https://drive.google.com/drive/folders/1gmeE3D7R62UAtuIFOB9j2M5cUPTwtsxK?usp=sharing), [Validation_Set](https://drive.google.com/drive/folders/1n5w45suVOyaqY84hltJhIZdtVFD9B224?usp=sharing), and [Testing_set](https://drive.google.com/drive/folders/1mYOf5USMGNcJRPcvRVJVV1uHEalG5RPl?usp=sharing) | [Paper Link](https://arxiv.org/abs/1711.10398) | Size: 2,806 images and 188, 282 instances<br>Number of Classes: 15<br>Resolution : range from 800 √ó 800 to 20,000 √ó 20,000 pixels  <br> Platforms: Google Earth, GF-2 and JL-1 satellite provided by the China Centre for Resources Satellite Data and Application, and aerial images provided by CycloMedia B.V  <br> Use: object detection in aerial images <br>|
| DOTA-v1.5 | [Training_Set](https://drive.google.com/drive/folders/1gmeE3D7R62UAtuIFOB9j2M5cUPTwtsxK?usp=sharing), [Validation_Set](https://drive.google.com/drive/folders/1n5w45suVOyaqY84hltJhIZdtVFD9B224?usp=sharing), and [Testing_set](https://drive.google.com/drive/folders/1mYOf5USMGNcJRPcvRVJVV1uHEalG5RPl?usp=sharing) | [Paper Link](https://arxiv.org/abs/1711.10398) | Size: 2,806 images with 403,318 instances in total<br>Number of Classes: 16<br>Resolution : range from 800 √ó 800 to 20,000 √ó 20,000 pixels  <br> *uses the same images as DOTA-v1.0, but the extremely small instances (less than 10 pixels) are also annotated. Moreover, a new category, ‚Äùcontainer crane‚Äù is added.  <br> Use: object detection in aerial images <br>|
| DOTA-v2.0 |You need to download DOTA-v1.0 images, and then download the extra images and annotations of [DOTA-v2.0](https://whueducn-my.sharepoint.com/:f:/g/personal/2014301200247_whu_edu_cn/EiJ3JsfWPqhPn2955rjdtxoBZUFYWCX2ZXOtbZ-GT0I7Qw?e=XjeBMB) | [Paper Link](https://arxiv.org/abs/1711.10398) | Size: 11,268 images and 1,793,658 instances<br>Number of Classes: 18<br>Resolution : range from 800 √ó 800 to 20,000 √ó 20,000 pixels  <br> *Compared to DOTA-v1.5, it further adds the new categories of ‚Äùairport‚Äù and ‚Äùhelipad‚Äù.  <br> Use: object detection in aerial images <br>|
| iSAID Dataset | [Training_Set](https://drive.google.com/drive/folders/19RPVhC0dWpLF9Y_DYjxjUrwLbKUBQZ2K?usp=sharing), [Validation_Set](https://drive.google.com/drive/folders/17MErPhWQrwr92Ca1Maf4mwiarPS5rcWM?usp=sharing), [Testing_Set](https://drive.google.com/drive/folders/1mYOf5USMGNcJRPcvRVJVV1uHEalG5RPl?usp=sharing), and [testing_images_info](https://drive.google.com/open?id=1nQokIxSy3DEHImJribSCODTRkWlPJLE3) | [Paper Link](http://openaccess.thecvf.com/content_CVPRW_2019/papers/DOAI/Zamir_iSAID_A_Large-scale_Dataset_for_Instance_Segmentation_in_Aerial_Images_CVPRW_2019_paper.pdf) | Size: 2,806 images with 655,451 object instances<br>Number of Classes: 15<br>Resolution : high resolution  <br> Platforms: Dota Dataset  <br> Use: semantic segmentation or object detection <br>|
| WHU dataset |[link](https://www.kaggle.com/datasets/xiaoqian970429/whu-building-dataset) - http://gpcv.whu.edu.cn/data/building_dataset.html | [Paper Link](https://arxiv.org/pdf/2208.00657v1.pdf) | Size: more than 220, 000 independent buildings <br>Number of Classes: 1<br>Resolution : 0.075 m spatial resolution and 450 km2 covering in Christchurch, New Zealand  <br> Platforms: QuickBird, Worldview series, IKONOS, ZY-3 and  6 neighboring satellite images covering 550 km2 on East Asia with 2.7 m ground resolution.<br> Use: Remote Sensing Building detection and change detection <br>|
| Vaihingen/Enz, Germany dataset |[link](https://seafile.projekt.uni-hannover.de/f/6a06a837b1f349cfa749/) | [Paper Link](https://arxiv.org/pdf/2206.09731v2.pdf) | Size: The data set contains 33 patches (of different sizes), each consisting of a true orthophoto (TOP) extracted from a larger TOP mosaic <br>Number of Classes:  five foreground classes and one background class <br>Resolution : 9 cm resolution <br> Platforms:  Intergraph/ZI DMC block, Leica ALS50 system and digital aerial cameras carried out by the German Association of Photogrammetry and Remote Sensing (DGPF) <br> Use: Urban Classification, 3D Building Reconstruction and Semantic Labeling <br>|
| Potsdam dataset |[link](https://seafile.projekt.uni-hannover.de/f/429be50cc79d423ab6c4/) | [Paper Link](https://arxiv.org/pdf/2206.09731v2.pdf) | Size: 38 patches (of the same size), each consisting of a true orthophoto (TOP) extracted from a larger TOP mosaic <br>Number of Classes: same category information as the Vaihingen dataset<br>Resolution : 6000x6000 pixels and 5cm resolution <br> Platforms:  Google Maps and OSM (DGPF)<br> Use: Semantic Segmentation <br>|
-->

## Related Repositories & Libraries
- [ConfigILM Library](https://github.com/lhackel-tub/ConfigILM)
- [awesome-RSVLM](https://github.com/om-ai-lab/awesome-RSVLM)
- [awesome-remote-sensing-vision-language-models](https://github.com/lzw-lzw/awesome-remote-sensing-vision-language-models)
- [awesome-remote-image-captioning](https://github.com/iOPENCap/awesome-remote-image-captioning)
 <!-- 
- [awesome-satellite-imagery-datasets][https://github.com/chrieke/awesome-satellite-imagery-datasets]
-->

---**Stay tuned for continuous updates and improvements! üöÄ**



